<!--
 * @Author: error: git config user.name && git config user.email & please set dead value or install git
 * @Date: 2022-07-08 17:04:15
 * @LastEditors: error: git config user.name && git config user.email & please set dead value or install git
 * @LastEditTime: 2022-07-12 17:27:15
 * @FilePath: \undefinedc:\Users\12645\Desktop\语音合成\语音转换\2022-07 调研\README.md
 * @Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->
# 语音转换调研（2020-2022-IEEE）


## 综述
1. [2021-An Overview of Voice Conversion and Its Challenges: From Statistical Modeling to Deep Learning](https://ieeexplore.ieee.org/document/9262021/)
2. [2022-A Survey on Generative Adversarial Networks based Models for Many-to-many Non-parallel Voice Conversion](https://ieeexplore.ieee.org/document/9756059)


## 模型
1. [2020-CycleGAN-VC-GP: Improved CycleGAN-based Non-parallel Voice Conversion](https://ieeexplore.ieee.org/document/9295938)，使用gradient panelty 使GAN模型收敛
2. [2021-AC-VC: Non-Parallel Low Latency Phonetic Posteriorgrams Based Voice Conversion](https://ieeexplore.ieee.org/document/9688277)，Almost Causal Voice Conversion，基于语音后验图的低延迟，any-to-many 语音转换。
3. [2020-Singing Voice Conversion Based on Non-Parallel Corpus](https://ieeexplore.ieee.org/document/9045773)，声码器：WORLD，SPTK提取特征，镜像GAN实现歌声转换。
4. [2021-Sequence-to-Sequence Emotional Voice Conversion With Strength Control](https://ieeexplore.ieee.org/document/9374921)，情感语音转换，可以控制情绪的强度和持续时间，采用基于注意力机制的seq2seq网络，同时设计情感编码器被将声学特征转换为情感嵌入向量。
5. [2020-Pitchnet: Unsupervised Singing Voice Conversion with Pitch Adversarial Network](https://ieeexplore.ieee.org/document/9054199)，歌唱语音转换，提出Pitch-Net。
6. [2021-IVCGAN:An Improved GAN for Voice Conversion](https://ieeexplore.ieee.org/document/9587053)，非并行数据，能够转换任意时长的样本。
7. [2020-Non-Parallel Sequence-to-Sequence Voice Conversion With Disentangled Linguistic and Speaker Representations](https://ieeexplore.ieee.org/document/8936924)，seq2seq模型，分离语音内容和说话人特征。
8. [2021-Defending Your Voice: Adversarial Attack on Voice Conversion](https://ieeexplore.ieee.org/document/9383529)，对语音转换执行对抗性攻击。
9.  [2020-CycleGAN-Based High-Quality Non-Parallel Voice Conversion with Spectrogram and WaveRNN](https://ieeexplore.ieee.org/document/9291952)，CycleGAN+WaveRNN，使用线性频谱图作为特征，效果优于 CycleGAN-VC2。
10. [2020-Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with CycleGAN](https://ieeexplore.ieee.org/document/9306487)，跨语言频谱、韵律转换，使用小波变换建模F0，训练两个CycleGAN
11. [2021-Transfer Learning From Speech Synthesis to Voice Conversion With Non-Parallel Training Data](https://ieeexplore.ieee.org/document/9380685)，TTS-VC迁移学习，基于seq2seq的语音合成改进。
12. [2021-Non-parallel Voice Conversion with Generative Attentional Networks](https://ieeexplore.ieee.org/document/9689340)，基于CycleGAN-VC，添加class activation map (CAM)。
13. [2021-Fragmentvc: Any-To-Any Voice Conversion by End-To-End Extracting and Fusing Fine-Grained Voice Fragments with Attention](https://ieeexplore.ieee.org/document/9413699)，Any-to-any 语音转换，提出了 FragmentVC，基于注意力机制。
14. [2021-Towards Low-Resource Stargan Voice Conversion Using Weight Adaptive Instance Normalization](https://ieeexplore.ieee.org/document/9415042)，低资源，基于StarGAN，使用speaker encoder和加权的AdaIN层。
15. [2021-Cyclegean: Cycle Generative Enhanced Adversarial Network for Voice Conversion](https://ieeexplore.ieee.org/document/9687948)，提出增强对抗性的CycleGAN，将原来的两个判别器变成target classifier 和 non-target classifier。
16. [2020-Emotional Voice Conversion Using Multitask Learning with Text-To-Speech](https://ieeexplore.ieee.org/document/9053255)，TTS+多任务学习
17. [2021-On Prosody Modeling for ASR+TTS Based Voice Conversion](https://ieeexplore.ieee.org/document/9688010)，从 linguistic representations 种直接预测韵律，提出 target text prediction。
18. [2020-One-Shot Voice Conversion by Vector Quantization](https://ieeexplore.ieee.org/document/9053854)，基于VQ的 one-shot VC。
19. [2020-F0-Consistent Many-To-Many Non-Parallel Voice Conversion Via Conditional Autoencoder](https://ieeexplore.ieee.org/document/9054734)，基于Autoencoder，使得生成语言的F0一致。
20. [2020-ConvS2S-VC: Fully Convolutional Sequence-to-Sequence Voice Conversion](https://ieeexplore.ieee.org/document/9113442)，Seq2Seq，全卷积结构，使用单个模型学习多个说话者之间的映射。
21. [2020-One-Shot Voice Conversion Algorithm Based on Representations Separation](https://ieeexplore.ieee.org/document/9240913)，RS-VC 模型+说话人验证模型 SVIGEN2E。
22. [2020-Lifter Training and Sub-Band Modeling for Computationally Efficient and High-Quality Voice Conversion Using Spectral Differentials](https://ieeexplore.ieee.org/document/9054490)，纯传统方法。
23. [2020-Multi-Speaker and Multi-Domain Emotional Voice Conversion Using Factorized Hierarchical Variational Autoencoder](https://ieeexplore.ieee.org/document/9054534)，情感语音转换，基于Factorized Hierarchical VAE。
24. [2020-VAW-GAN for Singing Voice Conversion with Non-parallel Training Data](https://ieeexplore.ieee.org/document/9306474)，基于VAW-GAN，编码器可以分离出singer identity和F0.
    


 <!-- 　<font color='red'>  </font> -->

## GAN-based non-parallel many-to-many voice conversion
> 总结自 "A Survey on Generative Adversarial Networks based Models for Many-to-many Non-parallel Voice Conversion"
1. [Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations](https://arxiv.org/abs/1804.02812)，两个stage，s1 训练带分类器的autoencoder，s2训练待分类器的GAN。
2. [StarGAN-VC:Non-parallel many-to-many voice conversion using star generative adversarial networks](https://ieeexplore.ieee.org/document/8639535)，<font color='red'> StarGAN-VC </font>，CycleGAN-VC 的拓展，新增了一个域分类器。
3. [StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice Conversion](https://arxiv.org/abs/1907.12279)，<font color='red'> StarGAN-VC2 </font>，使用源-目标条件损失，基于调制（Modulation）的条件。
4. [Fast Learning for Non-Parallel Many-to-Many Voice Conversion with Residual Star Generative Adversarial Networks](https://www.isca-speech.org/archive/pdfs/interspeech_2019/zhao19b_interspeech.pdf)，<font color='red'> Res-StarGAN-VC </font>，基于 StarGAN-VC，多了一个残差学习框架，即把 $G(x,c) \rightarrow G(x,c)+x$，可以加速训练。
5. [Many-To-Many Voice Conversion Using Conditional Cycle-Consistent Adversarial Networks](https://ieeexplore.ieee.org/abstract/document/9053726)，<font color='red'> CC-GAN-VC </font>，基于CycleGAN-VC，以源和目标说话人嵌入向量为条件（condition）；相比于CycleGAN，只有一个 conditional 生成器，判别器包含 N 个节点，效果和CycleGAN差不多，比StarGAN-VC好。
6. [Non-parallel Many-to-many Voice Conversion with PSR-StarGAN](http://www.interspeech2020.org/uploadfile/pdf/Mon-2-7-3.pdf)，<font color='red'> PSR-StarGAN-VC </font>，基于 StarGAN 改进三点，一使用 perceptual loss network，添加一个新的损失；二使用Switchable Normalization 替代 Batch Normalization；三加入残差连接提高训练速度。效果优于StarGAN-VC。
7. [Nonparallel Voice Conversion with Augmented Classifier Star Generative Adversarial Networks](https://arxiv.org/abs/2008.12604)，<font color='red'> A-StarGAN </font>，基于 StarGAN，将原来的GAN网络变成W-GAN克服模型的不稳定性，且将域分类器和判别器替换为一个多分类器网络。有两个模型，A-StarGAN-VC1 和 A-StarGAN-VC2.
8. [Towards Low-Resource Stargan Voice Conversion Using Weight Adaptive Instance Normalization](https://ieeexplore.ieee.org/document/9415042)，<font color='red'> WAStarGAN-VC </font>，基于 StarGAN-VC 和 StarGAN-VC2，改进后使其在低资源下能够保持VC的质量，改进之处在于，把 CIN 替换为 Weight Adaptive Instance Normalization (W-AdaIN)，移除 域分类器，使用speaker encoder网络提取speaker embedding。效果优于StarGAN-VC2。
9. [StarGAN-VC+ASR: StarGAN-based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition](https://arxiv.org/abs/2108.04395)，<font color='red'> StarGAN-VC+ASR </font>，有2个stage，s1训练一个正常的StarGAN，s2训练一个ASR来更新generator。  