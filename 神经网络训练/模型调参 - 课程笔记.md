
### 模型调参

1. 从一个好的工具包开始，如使用高质量的工具包的默认值、或者论文中给的值
2. 每次只调整一个参数，然后重新训练模型
3. 重复上面的步骤多次，得到所谓的直觉（insight），找到一些敏感的超参数及其合适的范围
	1. 例如，在优化器这块，一个调的好的 SGD 通常要比 Adam 要好，但是 Adam 对超参数不敏感，所以方便调整

### 超参数调整（手动）

1. 记录训练的日志和超参数
2. 重复实验是非常难的：存在环境、代码、随机数等的不同（随机性来源很多，可能是数据、 代码库甚至 dropout）

### 自动超参数调整

1. AutoML：自动化每一个步骤，包括数据清理、特征提取、模型选择等等
	1. 超参数优化：HPO
	2. 神经网络架构搜索：NAS

### HPO

确定每个超参数的范围：![[Pasted image 20230221154337.png]]

搜索空间可能是指数级的。

HPO 两大算法：
+ 黑盒：将一次训练的过程看成是黑箱，进去一套参数出来一个结果，好处就是适合任何的机器学习算法
+ 多置信：训练一次的开销很大，因此可以：
	+ 在采样的小数据集中进行训练
	+ 减小模型
	+ 对于不好的配置提前停止

黑盒算法：
1. grid search：网格搜索，本质就是暴力搜索，把搜索空间所有的超参数的组合都测一遍
	1. 优点：在搜索的范围较大时，可以保证最好的结果
	2. 缺点：维度诅咒，非常耗时
2. 随机搜索：随机在搜索空间中选择，且一共只选择 n 个配置
	1. 算是最好的选择，比 grid search 更有效
3. 贝叶斯优化（BO）：学习从超参数到目标函数（如loss或者 accuracy）的一个函数，然后当选择下一个超参数的配置的时候，基于前面的实验结果和当前的评估
	1. Surrogate model：拟合超参数到目标函数的模型，如可以使用各种回归模型，